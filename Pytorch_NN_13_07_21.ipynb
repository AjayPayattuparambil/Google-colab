{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_NN_13_07_21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfHH+jNwWbbng9W5Ca1P11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjayPayattuparambil/Google-colab/blob/main/Pytorch_NN_13_07_21.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rEnmDvzFswb",
        "outputId": "c250cd37-c47b-4f69-e193-b60382f12542"
      },
      "source": [
        "!pip install torch torchvision\n",
        "!pip install scikit-image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.16.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.5.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.19.0->scikit-image) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQgbKNrRGAdP"
      },
      "source": [
        "# import the necessary packages\n",
        "from collections import OrderedDict\n",
        "import torch.nn as nn\n",
        "def get_training_model(inFeatures=4, hiddenDim=8, nbClasses=3):\n",
        "\t# construct a shallow, sequential neural network\n",
        "\tmlpModel = nn.Sequential(OrderedDict([\n",
        "\t\t(\"hidden_layer_1\", nn.Linear(inFeatures, hiddenDim)),\n",
        "\t\t(\"activation_1\", nn.ReLU()),\n",
        "\t\t(\"output_layer\", nn.Linear(hiddenDim, nbClasses))\n",
        "\t]))\n",
        "\t# return the sequential model\n",
        "\treturn mlpModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SsCNdOsIqKD"
      },
      "source": [
        "Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKEzax9wIry7"
      },
      "source": [
        "# import the necessary packages\n",
        "from torch.optim import SGD\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_blobs\n",
        "import torch.nn as nn\n",
        "import torch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYR6QzDOJDBd"
      },
      "source": [
        "Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahZSg0kMIvle"
      },
      "source": [
        "def next_batch(inputs, targets, batchSize):\n",
        "\t# loop over the dataset\n",
        "\tfor i in range(0, inputs.shape[0], batchSize):\n",
        "\t\t# yield a tuple of the current batched data and labels\n",
        "\t\tyield (inputs[i:i + batchSize], targets[i:i + batchSize])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZGo-d-YJI9X",
        "outputId": "e4ba6812-374e-492a-a1bd-846db585f71f"
      },
      "source": [
        "# specify our batch size, number of epochs, and learning rate\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 10\n",
        "LR = 1e-2\n",
        "# determine the device we will be using for training\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"[INFO] training using {}...\".format(DEVICE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training using cuda...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJL-4yPCKJEY",
        "outputId": "b09764d5-f1af-431e-a216-375d5331a077"
      },
      "source": [
        "# generate a 3-class classification problem with 1000 data points,\n",
        "# where each data point is a 4D feature vector\n",
        "print(\"[INFO] preparing data...\")\n",
        "(X, y) = make_blobs(n_samples=1000, n_features=4, centers=3,\n",
        "\tcluster_std=2.5, random_state=95)\n",
        "# create training and testing splits, and convert them to PyTorch\n",
        "# tensors\n",
        "(trainX, testX, trainY, testY) = train_test_split(X, y,\n",
        "\ttest_size=0.15, random_state=95)\n",
        "trainX = torch.from_numpy(trainX).float()\n",
        "testX = torch.from_numpy(testX).float()\n",
        "trainY = torch.from_numpy(trainY).float()\n",
        "testY = torch.from_numpy(testY).float()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] preparing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rknOBcVHKLWo",
        "outputId": "99792d69-834f-49d9-d657-9d5b7afadc8a"
      },
      "source": [
        "# initialize our model and display its architecture\n",
        "mlp = get_training_model().to(DEVICE)\n",
        "print(mlp)\n",
        "# initialize optimizer and loss function\n",
        "opt = SGD(mlp.parameters(), lr=LR)\n",
        "lossFunc = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (hidden_layer_1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (activation_1): ReLU()\n",
            "  (output_layer): Linear(in_features=8, out_features=3, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hid8tZEHLSSy"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLpOywowKrkB",
        "outputId": "0c275768-f55a-4fc1-ab94-a0188e173e06"
      },
      "source": [
        "# create a template to summarize current training progress\n",
        "trainTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "# loop through the epochs\n",
        "for epoch in range(0, EPOCHS):\n",
        "\t# initialize tracker variables and set our model to trainable\n",
        "\tprint(\"[INFO] epoch: {}...\".format(epoch + 1))\n",
        "\ttrainLoss = 0\n",
        "\ttrainAcc = 0\n",
        "\tsamples = 0\n",
        "\tmlp.train()\n",
        "\t# loop over the current batch of data\n",
        "\tfor (batchX, batchY) in next_batch(trainX, trainY, BATCH_SIZE):\n",
        "\t\t# flash data to the current device, run it through our\n",
        "\t\t# model, and calculate loss\n",
        "\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\tpredictions = mlp(batchX)\n",
        "\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\t\t# zero the gradients accumulated from the previous steps,\n",
        "\t\t# perform backpropagation, and update model parameters\n",
        "\t\topt.zero_grad()\n",
        "\t\tloss.backward()\n",
        "\t\topt.step()\n",
        "\t\t# update training loss, accuracy, and the number of samples\n",
        "\t\t# visited\n",
        "\t\ttrainLoss += loss.item() * batchY.size(0)\n",
        "\t\ttrainAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\tsamples += batchY.size(0)\n",
        "\t# display model progress on the current training batch\n",
        "\ttrainTemplate = \"epoch: {} train loss: {:.3f} train accuracy: {:.3f}\"\n",
        "\tprint(trainTemplate.format(epoch + 1, (trainLoss / samples),\n",
        "\t\t(trainAcc / samples)))\n",
        " \n",
        "  \t# initialize tracker variables for testing, then set our model to\n",
        "\t# evaluation mode\n",
        "\ttestLoss = 0\n",
        "\ttestAcc = 0\n",
        "\tsamples = 0\n",
        "\tmlp.eval()\n",
        "\t# initialize a no-gradient context\n",
        "\twith torch.no_grad():\n",
        "\t\t# loop over the current batch of test data\n",
        "\t\tfor (batchX, batchY) in next_batch(testX, testY, BATCH_SIZE):\n",
        "\t\t\t# flash the data to the current device\n",
        "\t\t\t(batchX, batchY) = (batchX.to(DEVICE), batchY.to(DEVICE))\n",
        "\t\t\t# run data through our model and calculate loss\n",
        "\t\t\tpredictions = mlp(batchX)\n",
        "\t\t\tloss = lossFunc(predictions, batchY.long())\n",
        "\t\t\t# update test loss, accuracy, and the number of\n",
        "\t\t\t# samples visited\n",
        "\t\t\ttestLoss += loss.item() * batchY.size(0)\n",
        "\t\t\ttestAcc += (predictions.max(1)[1] == batchY).sum().item()\n",
        "\t\t\tsamples += batchY.size(0)\n",
        "\t\t# display model progress on the current test batch\n",
        "\t\ttestTemplate = \"epoch: {} test loss: {:.3f} test accuracy: {:.3f}\"\n",
        "\t\tprint(testTemplate.format(epoch + 1, (testLoss / samples),\n",
        "\t\t\t(testAcc / samples)))\n",
        "\t\tprint(\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] epoch: 1...\n",
            "epoch: 1 train loss: 0.690 train accuracy: 0.862\n",
            "epoch: 1 test loss: 0.555 test accuracy: 0.887\n",
            "\n",
            "[INFO] epoch: 2...\n",
            "epoch: 2 train loss: 0.507 train accuracy: 0.898\n",
            "epoch: 2 test loss: 0.431 test accuracy: 0.927\n",
            "\n",
            "[INFO] epoch: 3...\n",
            "epoch: 3 train loss: 0.414 train accuracy: 0.927\n",
            "epoch: 3 test loss: 0.353 test accuracy: 0.960\n",
            "\n",
            "[INFO] epoch: 4...\n",
            "epoch: 4 train loss: 0.345 train accuracy: 0.944\n",
            "epoch: 4 test loss: 0.295 test accuracy: 0.973\n",
            "\n",
            "[INFO] epoch: 5...\n",
            "epoch: 5 train loss: 0.291 train accuracy: 0.966\n",
            "epoch: 5 test loss: 0.250 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 6...\n",
            "epoch: 6 train loss: 0.246 train accuracy: 0.975\n",
            "epoch: 6 test loss: 0.214 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 7...\n",
            "epoch: 7 train loss: 0.211 train accuracy: 0.982\n",
            "epoch: 7 test loss: 0.185 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 8...\n",
            "epoch: 8 train loss: 0.182 train accuracy: 0.986\n",
            "epoch: 8 test loss: 0.162 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 9...\n",
            "epoch: 9 train loss: 0.160 train accuracy: 0.989\n",
            "epoch: 9 test loss: 0.143 test accuracy: 0.987\n",
            "\n",
            "[INFO] epoch: 10...\n",
            "epoch: 10 train loss: 0.142 train accuracy: 0.989\n",
            "epoch: 10 test loss: 0.128 test accuracy: 0.987\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}